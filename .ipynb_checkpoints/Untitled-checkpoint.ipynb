{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb237a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1dd19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "folders = glob('Datasets/Train/*')\n",
    "\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(1024, activation='relu')(x)\n",
    "prediction = Dense(1024, activation='relu')(x)\n",
    "prediction = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2386ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1719 images belonging to 4 classes.\n",
      "Found 483 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Datagenerator\n",
    "train_path = 'Datasets/Train'\n",
    "valid_path = 'Datasets/Test'\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255\n",
    "                                        )\n",
    "training_set = train_datagen.flow_from_directory('Datasets/Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Datasets/Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode = 'categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c66df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-9f97a2f885e7>:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 377s 7s/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 2.7241e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"face_recog.h5\",monitor=\"val_loss\",mode=\"min\",save_best_only = True,verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss',min_delta=0,patience =3,verbose=1,restore_best_weights=True)\n",
    "callbacks = [earlystop,checkpoint]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=1,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "model.save('vgg16.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ab4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# accuracies\n",
    "\n",
    "plt.plot(r.history['accuracy'])\n",
    "plt.plot(r.history['val_accuracy'])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c377869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 100356    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,815,044\n",
      "Trainable params: 100,356\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.input\n",
    "model.layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c92fd62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50176 into shape (1,224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-04f10f524013>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0minput_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0minput_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_im\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0minput_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vgg16.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 50176 into shape (1,224,224,3)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "image_size=[224,224]\n",
    "\n",
    "img=cv2.imread('Datasets/Test/test/Akhil1.jpg',0)\n",
    "input_original = img.copy()\n",
    "input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "input_im = cv2.resize(img, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "input_im = input_im / 255.\n",
    "input_im = input_im.reshape(1,224,224,3)\n",
    "\n",
    "model = load_model('vgg16.h5')\n",
    "pred = model.predict(img_array)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14cd5452",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-01509c08d1d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0minput_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetRandomImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Datasets/Test/celeb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0minput_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0minput_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-01509c08d1d5>\u001b[0m in \u001b[0;36mgetRandomImage\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"function loads a random images from a random folder in our test path \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mfolders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mrandom_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mpath_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_directory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class - \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfive_celeb_dict_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "classifier = load_model('vgg16.h5')\n",
    "five_celeb_dict = {\"[0]\": \"Akhil\", \n",
    "                      \"[1]\": \"Mahir\",\n",
    "                      \"[2]\": \"Manan\",\n",
    "                      \"[3]\": \"Omkar\",\n",
    "                      \n",
    "                     }\n",
    "\n",
    "five_celeb_dict_n = { \"celeb\": \"A\", \n",
    "                      \"test\": \"Mahir\",\n",
    "                      \"Manan\": \"Manan\",\n",
    "                      \"Omkar\": \"Omkar\",\n",
    "                      \n",
    "                      }\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    celeb =five_celeb_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, celeb, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + five_celeb_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"Datasets/Test/celeb\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    #print(classifier.predict(input_im))\n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e90f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - A\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "    input_im = getRandomImage(\"Datasets/Test/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50fd06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
